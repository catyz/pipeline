{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using TOAST operators with the SA pipeline\n",
    "#### An example showing how to use both SA and TOAST operators in one pipeline. Extends [Yuji's example](http://bolo.berkeley.edu/~chinoney/tmp/test/sa_offline_software.html). Still a work in progress, so some things may change in the future from this version!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: pyfftw found and activated.\n",
      "INFO: sqlite database /global/cscratch1/sd/yzh/data/ChileData/databases/pb2a-20200301/pb2a_boloid.db attached.\n",
      "INFO: sqlite database /global/cscratch1/sd/yzh/data/ChileData/databases/pb2a-20200301/pb2a_runid.db attached.\n",
      "INFO: sqlite database /global/cscratch1/sd/yzh/data/ChileData/databases/pb2a-20200301/pb2a_runid_g3.db attached.\n",
      "INFO: sqlite database /global/cscratch1/sd/yzh/data/ChileData/databases/pb2a-20200301/pb2a_focalplane.db attached.\n",
      "INFO: sqlite database /global/cscratch1/sd/yzh/data/ChileData/databases/pb2a-20200301/pb2a_scan_stat.db attached.\n",
      "INFO: sqlite database /global/cscratch1/sd/yzh/data/ChileData/databases/pb2a-20200301/pb2a_tuning.db attached.\n",
      "INFO: sqlite database /global/cscratch1/sd/yzh/data/ChileData/databases/pb2a-20200301/pb2a_slowdaq.db attached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to import slowdaq dependencies! Not crashing now in case those are not needed, but will crash if the slow data sources are attempted to be loaded.\n"
     ]
    }
   ],
   "source": [
    "#Relative imports for my setup. It's important our spt3g overrides TOAST's\n",
    "import sys\n",
    "sys.path.insert(0,'../simons_array_offline_software')\n",
    "sys.path.insert(0,'../spt3g_software_sa/build')\n",
    "sys.path.insert(0,'../software/toast/lib/python3.7/site-packages')\n",
    "sys.path.insert(0,'../simons_array_offline_software/kms_git/kms_plot')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import healpy as hp\n",
    "\n",
    "#Standard SA imports, see Yuji's example\n",
    "from simons_array_python import sa_pipeline_filters as sa_pf\n",
    "from simons_array_python import sa_pipeline_inputs as sa_pi\n",
    "from simons_array_python import sa_tod as sa_tod\n",
    "from simons_array_python import sa_observation as sa_ob\n",
    "from simons_array_python import sa_config\n",
    "from simons_array_python import sa_sql\n",
    "from simons_array_python import sa_pointing as sa_p\n",
    "from simons_array_python import sa_timestream_operators as sa_op\n",
    "\n",
    "#Import the TOAST wrapper\n",
    "from simons_array_python import sa_toast_tod\n",
    "\n",
    "#Standard TOAST imports\n",
    "import toast\n",
    "from toast.tod import (\n",
    "    OpSimNoise,\n",
    ")\n",
    "from toast.todmap import (\n",
    "    OpPointingHpix,\n",
    "    OpSimScan,\n",
    "    OpMapMaker\n",
    ")\n",
    "from toast.map import (\n",
    "    DistPixels\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the SA observation object and loading in data\n",
    "First, we read in the data from disk given a run ID. This populates the observation dictionary with a TOD list with 1 element. We set the default name of this TOD to 'data', although it can be set to whatever we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading SQL table pb2a_runid...done.\n"
     ]
    }
   ],
   "source": [
    "#Make an observation object given a run_id and sub_id\n",
    "\n",
    "runid = \"20100665.5\" #Vibration test scan ~1 hour\n",
    "\n",
    "obs = sa_ob.Observation(tuple(map(int,runid.split('.')))) \n",
    "\n",
    "obs.detectors = ['13.10_112.90B'] #Using 1 detector for simplicity\n",
    "obs._load_metadata()\n",
    "\n",
    "\n",
    "#Write some metadata to the observation that we're going to need later\n",
    "#Eventually this should be loaded in automatically from databases \n",
    "\n",
    "len_sec = (obs.last_mjd-obs.first_mjd)*24*3600\n",
    "obs.len_sec = len_sec\n",
    "obs.scan_freq = 5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data from g3 files for run_id=20100665, run_subid=5 . . . \n",
      "Reading SQL table pb2a_runid_g3file...done.\n",
      "Reading SQL table pb2a_g3file...done.\n",
      "Reading SQL table pb2a_boloid...done.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Run20100665.5: reading following files: Run20100665_002.g3.\n",
      "INFO: Run20100665.5: frame (total, first, last)=(154, 10, 11).\n",
      "WARNING: 14/5480 detector name(s) are passed to bolo_name_from_name function, but not existent in the database: PB20.13.11_Comb29Ch07,PB20.13.13_Comb02Ch35,PB20.13.13_Comb02Ch36,PB20.13.13_Comb02Ch37,PB20.13.13_Comb02Ch38,PB20.13.13_Comb21Ch35,PB20.13.13_Comb21Ch36,PB20.13.13_Comb23Ch38,PB20.13.15_Comb16Ch37,PB20.13.15_Comb16Ch38,PB20.13.15_Comb21Ch39,PB20.13.28_Comb10Ch36,PB20.13.28_Comb18Ch39,PB20.13.31_Comb22Ch36.\n",
      "Setting input name to data\n"
     ]
    }
   ],
   "source": [
    "#SA operator to read in the data from the g3 files\n",
    "#For this particular run ~1 hour, it takes about a minute to load in everything\n",
    "#TOAST has ways to parallelize data I/O, but maybe we want to keep that separate\n",
    "\n",
    "pi = sa_pi.InputLevel0CachedByObsID(\n",
    "    all_detectors = obs.detectors,\n",
    "    n_per_cache = 1,\n",
    "    load_slowdaq = False,\n",
    "    load_hwp = False,\n",
    "    load_dets = True, \n",
    "    load_g3 = True,\n",
    "    ignore_faulty_frame = True,\n",
    "    record_frame_time = True\n",
    ")\n",
    "\n",
    "sa_operator = sa_pf.OperatorDataInitializer(pi)\n",
    "\n",
    "sa_operator.filter_obs(obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing the TOAST wrapper \n",
    "Now that the data has been read in, we can initialize the TOAST wrapper. It moves the cache content of each TOD in the SA TOD list into a combined TOAST TOD cache with the appropriate prefixes. After running the wrapper, the idea is that the top level \"obs.tod_list\" now behaves like a TOAST TOD object, and its elements \"obs.tod_list[i]\" behave like SA TODs. TOAST operators then act at the list level, and SA operators act on the elements. They share one top level cache, which both types of operators how to access given a prefix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 458\n"
     ]
    }
   ],
   "source": [
    "#Prepare some parameters to pass to TOAST\n",
    "\n",
    "nsamp = len(obs.tod_list[0].read('13.10_112.90B-I'))\n",
    "print('Number of samples: %i' % nsamp)\n",
    "toast_dets = obs.detectors\n",
    "\n",
    "\n",
    "#Initialize the TOAST wrapper \n",
    "\n",
    "obs.tod_list = sa_toast_tod.TodToastWrapper(\n",
    "    tod_list = obs.tod_list,\n",
    "    mpicomm = None,\n",
    "    detectors = toast_dets,\n",
    "    samples = nsamp,\n",
    "    detindx = {x[0]:x[1] for x in zip(toast_dets, range(len(toast_dets)))},\n",
    "    detranks = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up some more metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs.tod_list.set_toast_prefix('data') #Temporary fix, won't need this later\n",
    "obs['tod'] = obs.tod_list #TOAST expects the TOD object under a key called 'tod'\n",
    "#obs['noise'] = obs.tod_list.noise #Load in detector noise properties (made up for now)\n",
    "\n",
    "#The TOAST mapmaker requires flags, so we will write in manually for now\n",
    "obs.tod_list.write_common_flags(flags = np.zeros(nsamp, dtype=np.int8))\n",
    "\n",
    "for det in toast_dets:\n",
    "    obs.tod_list.write_flags(detector=det, flags = np.zeros(nsamp, dtype=np.int8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create the TOAST data object, which wraps the SA observation object with an MPI communicator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "comm = toast.Comm(groupsize=1)\n",
    "data = toast.Data(comm)\n",
    "data.obs.append(obs)\n",
    "\n",
    "sa_obs = data.obs[0] # For convenience"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check out the keys present in the observation dictionary and the keys of the top level TOAST cache. Notice the prefix 'data' in the cache keys. This is because for this example, the SA data initializer only loaded in one TOD, which we called \"data.\" If multiple TODs are loaded in, we would see more prefixes here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['tod_list', 'detectors', 'obs_id', 'name', 'intervals', 'baselines', 'noise', 'hwmap', 'id', 'site', 'telescope', 'site_id', 'telescope_id', 'fpradius', 'weather', 'start_time', 'altitude', 'season', 'date', 'MJD', 'focalplane', 'first_mjd', 'last_mjd', 'features', 'field', 'source', 'scan_name', 'len_sec', 'scan_freq', 'tod'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sa_obs.__dict__.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data_13.10_112.90B-I',\n",
       " 'data_13.10_112.90B-Q',\n",
       " 'data_bolo_time',\n",
       " 'data_common_flags',\n",
       " 'data_flags_13.10_112.90B',\n",
       " 'data_frame_faulty',\n",
       " 'data_frame_total',\n",
       " 'data_raw_acu_seq',\n",
       " 'data_raw_antenna_time_mjd',\n",
       " 'data_raw_az_command',\n",
       " 'data_raw_az_pos',\n",
       " 'data_raw_az_rate',\n",
       " 'data_raw_az_rate_command',\n",
       " 'data_raw_el_command',\n",
       " 'data_raw_el_pos',\n",
       " 'data_raw_el_rate',\n",
       " 'data_raw_el_rate_command',\n",
       " 'data_raw_in_control',\n",
       " 'data_raw_scan_flag',\n",
       " 'data_raw_state']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cache = sa_obs.tod_list.cache\n",
    "cache.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply SA data processing operators\n",
    "Now we can apply some common SA operators. In this example, we apply the scan corrector, interpolator, and boresight calculator. The results will be used by TOAST operators later on. Note that the SA operators act at the observation level (which is an attribute of the full data object)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW VECTOR LENGTHS! 300 300\n",
      "WARNING: Overwriting field name data_corrected_antenna_time_mjd in TOD\n",
      "WARNING: Overwriting field name data_gcp_gaps_time in TOD\n",
      "WARNING: Overwriting field name data_gcp_gaps in TOD\n",
      "NEW VECTOR LENGTHS! 300 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Applying pipeline filter: <class 'simons_array_python.sa_pipeline_filters.OperatorScanCorrector'>\n",
      "INFO: Applying pipeline filter: <class 'simons_array_python.sa_pipeline_filters.OperatorScanCorrector'>\n"
     ]
    }
   ],
   "source": [
    "#SA Operator to correct for stuff like backward encoder timestamps, duplicated encoder samples, etc\n",
    "#Can use OperatorComposite to run similar operators together\n",
    "\n",
    "scan_corrector = sa_pf.OperatorComposite(\n",
    "    sa_pf.OperatorScanCorrector('raw_scan_flag', 'raw_el_pos', 'raw_antenna_time_mjd'),\n",
    "    sa_pf.OperatorScanCorrector('raw_scan_flag', 'raw_az_pos', 'raw_antenna_time_mjd')\n",
    ")\n",
    "scan_corrector.filter_obs(sa_obs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SA detectors sample at a different rate than the encoder, so we need to interpolate one to the other\n",
    "\n",
    "interpolator = sa_pf.OperatorTelescopeDataInterpolator(prefix='corrected_')\n",
    "interpolator.filter_obs(sa_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'prefix'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-66d67300d5ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Lastly, we compute the boresight quaternions in equatorial coordinates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcompute_boresight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msa_p\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mComputeBoresightQuaternions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mcompute_boresight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter_obs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msa_obs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'prefix'"
     ]
    }
   ],
   "source": [
    "#Lastly, we compute the boresight quaternions in equatorial coordinates\n",
    "\n",
    "compute_boresight = sa_p.ComputeBoresightQuaternions()\n",
    "compute_boresight.filter_obs(sa_obs) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check out the new entries that have been written to the cache. We see that the boresight operator created a new entry called \"data_boresight\" amongst others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data_13.10_112.90B-I',\n",
       " 'data_13.10_112.90B-Q',\n",
       " 'data_acu_seq',\n",
       " 'data_az_command',\n",
       " 'data_az_pos',\n",
       " 'data_az_rate',\n",
       " 'data_az_rate_command',\n",
       " 'data_bolo_time',\n",
       " 'data_common_flags',\n",
       " 'data_corrected_antenna_time_mjd',\n",
       " 'data_corrected_az_pos',\n",
       " 'data_corrected_el_pos',\n",
       " 'data_el_command',\n",
       " 'data_el_pos',\n",
       " 'data_el_rate',\n",
       " 'data_el_rate_command',\n",
       " 'data_flags_13.10_112.90B',\n",
       " 'data_frame_faulty',\n",
       " 'data_frame_total',\n",
       " 'data_gcp_gaps',\n",
       " 'data_gcp_gaps_time',\n",
       " 'data_in_control',\n",
       " 'data_reverse_time_indices',\n",
       " 'data_scan_flag',\n",
       " 'data_state']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cache.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying TOAST operators \n",
    "Now that the data has been cleaned up and the boresight has been calculated, we can start running some simulations using TOAST operators. In this example, we will make a pointing matrix, scan a Planck temperature map into a TOD, add some detector noise to it, and bin it into a map. Note that the TOAST operators act at the data object level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TOAST operator for calculating the pointing matrix\n",
    "\n",
    "pointing = OpPointingHpix(\n",
    "    nside=512,\n",
    "    nest=True,\n",
    "    mode=\"I\",\n",
    "    pixels='pixels',\n",
    "    weights='weights'\n",
    ")\n",
    "pointing.exec(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in an input map to scan, and distribute the pixels. The TOAST scan operator (immediately following) requires this format\n",
    "\n",
    "distmap = DistPixels(\n",
    "    data, \n",
    "    nnz=1, \n",
    "    dtype=np.float64,\n",
    "    pixels='pixels'\n",
    ")\n",
    "distmap.read_healpix_fits('input_map.fits') #This is an Planck temperature map, but we can use whatever we want "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TOAST operator for scanning the input map into a timestream\n",
    "\n",
    "op_simscan = OpSimScan(\n",
    "    distmap = distmap,\n",
    "    pixels = 'pixels',\n",
    "    weights = 'weights',\n",
    "    out = 'mc1' #Store it in the cache with this prefix. Monte carlo 1\n",
    ")\n",
    "op_simscan.exec(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TOAST operator for simulating detector noise\n",
    "\n",
    "op_simnoise = OpSimNoise(\n",
    "    out = 'mc1', #Automatically coadds with signal, although we don't have to\n",
    "    realization = 0,\n",
    "    component = 0,\n",
    "    noise = 'noise',\n",
    "    rate = 152.6 #Not usually set here, but currently there's a bug so I'm asserting it for now\n",
    ")\n",
    "op_simnoise.exec(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TOAST native mapmaker\n",
    "\n",
    "mapmaker = OpMapMaker(\n",
    "    nside = 512,\n",
    "    nnz = 1,\n",
    "    name = 'mc1', #Map the simulated signal + detector noise\n",
    "    pixels = 'pixels',\n",
    "    weights = 'weights',\n",
    "    intervals = None,\n",
    "    baseline_length = None,\n",
    "    use_noise_prior = False,\n",
    "    outdir = \"./map\"\n",
    ")\n",
    "mapmaker.exec(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the map!\n",
    "\n",
    "plt.figure(figsize=[18, 12])\n",
    "hits = hp.read_map(\"./map/hits.fits\")\n",
    "imax = np.argmax(hits)\n",
    "lon, lat = hp.pix2ang(hp.get_nside(hits), imax, lonlat=True)\n",
    "crop = np.where(hits == 0)\n",
    "hits[crop] = hp.UNSEEN\n",
    "hp.mollview(hits, xsize=1200, sub=[2, 2, 1], title=\"hits\")\n",
    "hp.gnomview(\n",
    "    hits,\n",
    "    rot=(lon-5, lat),\n",
    "    xsize=1500,\n",
    "    reso=1.0,\n",
    "    sub=[2, 2, 2],\n",
    "    title=\"hits, lon={:.2f}deg, lat={:.2f}deg\".format(lon, lat),\n",
    ")\n",
    "\n",
    "binned = hp.read_map(\"./map/binned.fits\")\n",
    "binned[binned == 0] = hp.UNSEEN\n",
    "hp.mollview(binned, xsize=1200, sub=[2, 2, 3], title=\"binned\")\n",
    "hp.gnomview(\n",
    "    binned,\n",
    "    rot=(lon-5, lat),\n",
    "    xsize=1500,\n",
    "    reso=1.0,\n",
    "    sub=[2, 2, 4],\n",
    "    title=\"binned, lon={:.2f}deg, lat={:.2f}deg\".format(lon, lat),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top row contains hit maps and the bottom row contains the binned maps. If it looks weird due to the line spacing, it's probably because this observation was a vibration test run, where the telescope slews back and forth really fast."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting TODs\n",
    "Now let's plot the real and simulated TODs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Actual data TOD loaded in from the g3 files\n",
    "\n",
    "data_tod = cache['data_13.10_112.90B-I'] \n",
    "plt.plot(data_tod)\n",
    "plt.title('Real/data TOD')\n",
    "plt.xlabel('Samples')\n",
    "plt.ylabel('ADC counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simulated TOD, obtained by scanning the Planck temperature map plus some detector noise\n",
    " \n",
    "simulated_tod = cache['mc1_13.10_112.90B']\n",
    "\n",
    "#Set up some fake gain for spectra plotting purposes for now. TOAST has an operator for gain application\n",
    "data_max = max(data_tod)\n",
    "data_min = min(data_tod)\n",
    "data_mean = np.mean(data_tod)\n",
    "sim_max = max(simulated_tod)\n",
    "sim_min = min(simulated_tod)\n",
    "conversion = (data_max - data_min) / (sim_max - sim_min)\n",
    "\n",
    "cache['mc1_13.10_112.90B'] = cache['mc1_13.10_112.90B']*conversion + data_mean\n",
    "\n",
    "plt.plot(cache['mc1_13.10_112.90B'])\n",
    "plt.title('Simulated signal + detector noise TOD')\n",
    "plt.xlabel('Samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have two different flavors of TODs: 'data', which we read in from file, and 'mc1' which we simulated. The SA operators currently don't know about 'mc1', so before we apply any subsequent SA operators, we need to make that prefix known to them. We should probably discuss the best way to do this, but for now I will do it manually to show how subsequent SA operators should behave on new TOD flavors generated by TOAST. This isn't how we'll do it eventually, so feel free to ignore the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Temporary fix for demonstration purposes, feel free to skip ###\n",
    "\n",
    "sa_obs.tod_list.update_tod_list('mc1')\n",
    "input_name_list = sa_obs.tod_list.get_input_name_list()\n",
    "\n",
    "for key in cache.keys():\n",
    "    if input_name_list[0] in key and toast_dets[0] not in key:\n",
    "        new_key = key.replace(input_name_list[0]+'_', input_name_list[1]+'_')\n",
    "        cache[new_key] = cache[key]\n",
    "    if input_name_list[1] in key:\n",
    "        cache[key+'-I'] = cache[key]\n",
    "\n",
    "for tod in sa_obs.tod_list:\n",
    "    tod.cache = cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the top level cache again. Note the two prefixes, \"data\" and \"mc1\", correspond to different flavors of the TODs. Shared information like the boresight have been copied from one TOD to the other, thereby preserving modularity. When SA operators iterate through this new TOD list, they will know how to access each flavor based on the prefixes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying SA timestream filtering operators\n",
    "To bring things back full circle, let's apply another SA operator to represent the timestream filtering that would take place after the simulations are done. OperatorTODEvalSpectrum computes the spectrum of all detectors in all TODs of the list. In this example we just have one detector and two TODs, so we should get back two spectra plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set where our plots go\n",
    "\n",
    "file_factory = sa_op.PlotFileFactoryFlatDirectory(root = './spec')\n",
    "\n",
    "\n",
    "#Compute the spectrum, looping over all dets in all TODs\n",
    "\n",
    "compute_spectrum = sa_op.OperatorTODEvalSpectrum(\n",
    "    tod_attr='I',\n",
    "    eval_attr_name=None,\n",
    "    tod_unit='ADC',\n",
    "    scan_mask_df=1,\n",
    "    scan_freq=None, \n",
    "    plot_file_factory=file_factory,\n",
    "    plot_file_suffix=None,\n",
    "    plot_kwds={},\n",
    "    compute_subscans=False,\n",
    "    perform_fit=True,\n",
    "    detrend_per_subscan=False,\n",
    ")\n",
    "\n",
    "compute_spectrum.filter_obs(sa_obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code currently writes both plots to the same file, so I saved them separately instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='./spec/20100857.5/data_spec.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='./spec/20100857.5/mc1_spec.png') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get two spectra as expected, one for actual data (top) and one for our simulation (bottom). I made up some (probably outrageous) noise properties and did an awkward gain conversion, so I wouldn't analyze the second spectra too closely. This is just a demonstration of how things could work.\n",
    "\n",
    "### Thanks for reading!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CMB 20200630",
   "language": "python",
   "name": "cmbenv-20200630"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
